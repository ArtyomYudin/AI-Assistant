import asyncio
import logging
import time
from typing import List, Optional

from langchain_core.documents import Document
from langchain_core.messages import HumanMessage, AIMessage

from config.rag_config import RAGConfig
from core.chat_history import RedisChatHistory
from core.document_loader import load_documents_from_directory
from core.milvus_manager import MilvusManager
from core.splitters import SplitterManager
from core.utils import count_tokens, truncate_text_by_tokens
from core.embedding_cache import RedisEmbeddingCache

logger = logging.getLogger(__name__)

class RAGCore:
    """
      –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞:
      - –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
      - –ø–æ–∏—Å–∫ –ø–æ Milvus (–≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ)
      - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
      - –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ Redis
      - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–µ–π –¥–∏–∞–ª–æ–≥–∞
      - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM
    """
    def __init__(self, config: Optional[RAGConfig] = None):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.config = config or RAGConfig()

        # –ú–µ–Ω–µ–¥–∂–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞ (—Ö—Ä–∞–Ω–∏—Ç –ø–µ—Ä–µ–ø–∏—Å–∫—É)
        self.history = RedisChatHistory(
            session_id = "default",  # –ø–æ—Ç–æ–º –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–π session_id –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞
            host = self.config.REDIS_HOST,
            port = self.config.REDIS_PORT,
            ttl_days = self.config.HISTORY_TTL_DAYS,
            max_messages = self.config.MAX_HISTORY_MESSAGES
        )

        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Milvus (–≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ)
        self.milvus = MilvusManager(
            uri = self.config.MILVUS_URI,
            collection_name = self.config.COLLECTION_NAME,
            recreate = self.config.RECREATE_COLLECTION
        )

        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–ø–ª–∏—Ç—Ç–∏–Ω–≥–æ–º —Ç–µ–∫—Å—Ç–∞ (–ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º, —á–∞–Ω–∫–∞–º)
        self.splitters = SplitterManager(
            self.config.CHUNK_SIZE,
            self.config.CHUNK_OVERLAP
        )

        # –õ–µ–Ω–∏–≤–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã (—Å–æ–∑–¥–∞—é—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ)
        self._embeddings = None
        self._llm = None

        # –†–µ—Ç—Ä–∏–≤–µ—Ä (–ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É)
        self.retriever = None

        # –¶–µ–ø–æ—á–∫–∞ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç —Å –∏—Å—Ç–æ—Ä–∏–µ–π –∏ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º
        self.qa_chain_with_history = None

        # –ö—ç—à —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ Redis
        self.embedding_cache = RedisEmbeddingCache(
            host = self.config.REDIS_HOST,
            port = self.config.REDIS_PORT,
            ttl = self.config.REDIS_TTL
        )

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.close()

    def __repr__(self):
        return f"<RAGConfig mode={self.config.MODE}, collection={self.config.COLLECTION_NAME}>"

    def __str__(self):
        return self.__repr__()

    @property
    # def embeddings(self):
    #     if self._embeddings is None:
    #         from langchain_openai import OpenAIEmbeddings
    #         self._embeddings = OpenAIEmbeddings(
    #             model=self.config.EMBEDDING_NAME,
    #             api_key="EMPTY",
    #             base_url=self.config.EMBEDDING_BASE_URL,
    #             embedding_ctx_length=512,
    #             timeout=60,
    #         )
    #     return self._embeddings
    def embeddings(self):
        """
        –õ–æ–∫–∞–ª—å–Ω–∞—è –∏–ª–∏ –≤–Ω–µ—à–Ω—è—è –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
        –ü—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ —Å–æ–∑–¥–∞—ë—Ç—Å—è –æ–±—ä–µ–∫—Ç.
        """
        if self._embeddings is None:
            from core.local_embeddings import LocalEmbeddings
            self._embeddings = LocalEmbeddings(
                model = self.config.EMBEDDING_NAME,
                base_url = self.config.EMBEDDING_BASE_URL,
                timeout = 60,
            )
        return self._embeddings

    @property
    def llm(self):
        """
        LLM-–∫–ª–∏–µ–Ω—Ç (ChatOpenAI API-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π).
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤.
        """
        if self._llm is None:
            from langchain_openai import ChatOpenAI
            self._llm = ChatOpenAI(
                model = self.config.LLM_NAME,
                api_key = "EMPTY",
                base_url =self.config.LLM_BASE_URL,
                max_tokens = self.config.LLM_MAX_TOKEN,
                temperature = self.config.LLM_TEMPERATURE,
                streaming = True,
                extra_body = {"chat_template_kwargs": {"enable_thinking": False}}
            )
        return self._llm

    def get_history(self, session_id: str) -> RedisChatHistory:
        """
        –í—ã–¥–∞–µ–º –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π session_id.
        """
        return RedisChatHistory(
            session_id = session_id,
            host = self.config.REDIS_HOST,
            port = self.config.REDIS_PORT,
            ttl_days = self.config.HISTORY_TTL_DAYS,
            max_messages=self.config.MAX_HISTORY_MESSAGES
        )

    def load_documents(self, directory: Optional[str] = None) -> List[Document]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
        –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è config.DATA_DIR.
        """
        directory = directory or self.config.DATA_DIR
        return load_documents_from_directory(directory)

    async def setup_vectorstore(self, documents: List[Document]) -> None:
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ Milvus:
        - –Ω–∞—Ä–µ–∑–∫–∞ –Ω–∞ —á–∞–Ω–∫–∏
        - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        - –≤—Å—Ç–∞–≤–∫–∞ –≤ Milvus
        """
        if not documents:
            logger.warning("–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
            return

        # –°–ø–ª–∏—Ç–∏–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º / —á–∞–Ω–∫–∞–º
        processed = self.splitters.split_by_headers(documents)
        if not processed:
            logger.warning("–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        texts = [d.page_content for d in processed]
        sources = [d.metadata.get("source","N/A") for d in processed]
        hashes = [d.metadata.get("hash") for d in processed]

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞
        try:
            dense_vectors = await self.embeddings.embed_documents(texts)
        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö: %s", e)
            raise
        dense_dim = len(dense_vectors[0]) if dense_vectors else 0
        if dense_dim <= 0:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞")
            return

        # –°–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –≤ Milvus (–µ—Å–ª–∏ –Ω–µ—Ç)
        await self.milvus.create_collection_if_needed(dense_dim=dense_dim)

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
        rows = [
            {"text": t,
             "source": s,
             "hash": h or "",
             "dense_vector": dv} for t, s, dv, h in zip(texts, sources, dense_vectors, hashes)]

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique = await self.milvus.ensure_not_duplicate_rows(rows)
        if not unique:
            logger.info("–í—Å–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —É–∂–µ –≤ –∏–Ω–¥–µ–∫—Å–µ")
            return

        # –í—Å—Ç–∞–≤–∫–∞ —á–∞–Ω–∫–∞–º–∏ (batch insert)
        bs = self.config.INDEX_BATCH_SIZE
        total = 0
        for i in range(0, len(unique), bs):
            total += await self.milvus.insert_records(unique[i:i+bs])
        logger.info("–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: %d", total)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –≤ –ø–∞–º—è—Ç—å —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –≤—Å—Ç–∞–≤–∫–∏
        await self.milvus.client.load_collection(self.milvus.collection_name)
        logger.info("–ö–æ–ª–ª–µ–∫—Ü–∏—è %s –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ –ø–∞–º—è—Ç—å", self.milvus.collection_name)

    async def _get_embedding_cached(self, query: str) -> Optional[List[float]]:
        """–ø—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞ –∏–∑ Redis"""
        cached = self.embedding_cache.get(query)
        if cached is not None:
            return cached
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            emb = await self.embeddings.embed_query(query)
            self.embedding_cache.set(query, emb)
            return emb
        except Exception as e:
            logger.warning("–û—à–∏–±–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞: %s", e)
            return None

    def create_retriever(self, k: Optional[int] = None, fetch_k: Optional[int] = None) -> None:
        """
        –°–æ–∑–¥–∞—ë—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ—Ç—Ä–∏–≤–µ—Ä:
        - –∏—â–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ Milvus
        - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        """
        k = k or self.config.K
        fetch_k = fetch_k or self.config.FETCH_K

        async def retrieve(query: str) -> List[Document]:
            if not query.strip():
                return []

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–ª–ª–µ–∫—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if not await self.milvus.client.has_collection(self.milvus.collection_name):
                logger.warning("–ö–æ–ª–ª–µ–∫—Ü–∏—è %s –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", self.milvus.collection_name)
                return []

            # –ü–æ–¥—Å—Ç—Ä–∞—Ö–æ–≤–∫–∞: –∑–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –ø–µ—Ä–µ–¥ –ø–æ–∏—Å–∫–æ–º
            await self.milvus.ensure_collection_loaded(self.milvus.collection_name)

            dense = await self._get_embedding_cached(query)

            # –î–µ–ª–∞–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ (–ø–æ –≤–µ–∫—Ç–æ—Ä—É + —Ç–µ–∫—Å—Ç—É)
            return await self.milvus.hybrid_search(
                query_text = query,
                query_dense = dense,
                fetch_k = fetch_k,
                top_k = k,
                reranker_endpoint = self.config.RERANKER_BASE_URL
            )

        self.retriever = retrieve
        logger.info("–†–µ—Ç—Ä–∏–≤–µ—Ä —Å–æ–∑–¥–∞–Ω (k=%d, fetch_k=%d)", k, fetch_k)

    def _build_context(self, docs: List[Document], session_id: str) -> tuple[str, str]:
        """
            –§–æ—Ä–º–∏—Ä—É–µ—Ç —á–∞—Å—Ç–∏ –¥–ª—è LLM:
            - –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ (–æ–±—Ä–µ–∑–∞–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è)
            - –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (—Å —É—á—ë—Ç–æ–º –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤)
            - —É—á–∏—Ç—ã–≤–∞–µ—Ç –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (context, history_text).
        """
        # –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ ‚Äî –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ MAX_HISTORY_MESSAGES —Å–æ–æ–±—â–µ–Ω–∏–π
        history_obj = self.get_history(session_id)
        hist = history_obj.get_messages()
        hist = hist[-self.config.MAX_HISTORY_MESSAGES:]  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–æ–æ–±—â–µ–Ω–∏–π
        # –û–±—Ä–µ–∑–∞–µ–º –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ —Ä–∞–∑—É–º–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä 500
        history_text = "\n".join(
            f"{m.type.capitalize()}: {truncate_text_by_tokens(m.content, 500)}" for m in hist
        )

        # –°—á–∏—Ç–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        available = self.config.MAX_CONTEXT_TOKENS - self.config.RESERVED_FOR_COMPLETION \
                    - count_tokens(history_text) - self.config.RESERVED_FOR_OVERHEAD
        if available <= 0:
            logger.warning(
                f"[{session_id}] –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ <= 0 ({available}). "
                f"–î–æ–±–∞–≤–ª—è–µ–º —Ö–æ—Ç—è –±—ã –ø–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç."
            )
            # fallback: –¥–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
            if docs:
                text = f"[–ò—Å—Ç–æ—á–Ω–∏–∫: {docs[0].metadata.get('source', 'N/A')}] {docs[0].page_content.strip()}"
                return truncate_text_by_tokens(text, 500), history_text
            else:
                return "", history_text

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–æ –∏—Å—á–µ—Ä–ø–∞–Ω–∏—è –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
        parts, used = [], 0
        for d in sorted(docs, key=lambda x: x.metadata.get("score", 0), reverse=True):
            text = f"[–ò—Å—Ç–æ—á–Ω–∏–∫: {d.metadata.get('source', 'N/A')}] {d.page_content.strip()}\n"
            tks = count_tokens(text)
            if used + tks > available:
                remain = available - used
                if remain > 50:
                    parts.append(truncate_text_by_tokens(text, remain))
                break
            parts.append(text)
            used += tks

        context = "".join(parts).strip()

        # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤—Å—ë –µ—â—ë –ø—É—Å—Ç–æ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ), –¥–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —á–∞—Å—Ç–∏—á–Ω–æ
        if not context and docs:
            context = truncate_text_by_tokens(docs[0].page_content.strip(), min(available, 500))

        return context, history_text

    def _build_prompt(self, mode: str, question: str, context: str, history_text: str) -> str:
        """
        –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –ø—Ä–æ–º–ø—Ç–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã RAG
        """
        if mode == "rag":
            return self.config.QA_PROMPT_RAG_EN.format(context=context, chat_history=history_text, question=question)
        elif mode == "hybrid":
            return self.config.QA_PROMPT_HYBRID_EN.format(context=context, chat_history=history_text, question=question)
        elif mode == "llm_only":
            return self.config.QA_PROMPT_LLM_ONLY_EN.format(chat_history=history_text, question=question)
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º: {mode}")

    def create_qa_generator(self) -> None:
        """
        –°–æ–∑–¥–∞—ë—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä Q&A:
        - –∏—â–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã
        - —Å—Ç—Ä–æ–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç
        - –≤—ã–∑—ã–≤–∞–µ—Ç LLM –ø–æ—Ç–æ–∫–æ–≤–æ
        - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞
        """
        if not self.retriever:
            raise ValueError("–†–µ—Ç—Ä–∏–≤–µ—Ä –Ω–µ —Å–æ–∑–¥–∞–Ω. –í—ã–∑–æ–≤–∏—Ç–µ create_retriever().")
        async def generate_answer_stream(question: str, session_id: str = "default"):
            start_time = time.time()
            logger.debug(f"[{session_id}] üöÄ –ù–∞—á–∞–ª –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–æ–ø—Ä–æ—Å–∞: {question[:100]}...")

            if not question.strip():
                logger.warning(f"[{session_id}] –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å")
                yield "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å."
                return

                # –°—Ä–∞–∑—É –æ—Ç–¥–∞—ë–º –ø–µ—Ä–≤—ã–π —Ç–æ–∫–µ–Ω ‚Äî "–æ—Ç–∫–ª–∏–∫"
            yield "‚è≥ –î—É–º–∞—é –Ω–∞–¥ –≤–∞—à–∏–º –≤–æ–ø—Ä–æ—Å–æ–º...\n"

            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∏ –∑–∞–≥—Ä—É–∑–∫—É –∏—Å—Ç–æ—Ä–∏–∏
            embedding_start = time.time()
            embedding_task = asyncio.create_task(self._get_embedding_cached(question))
            history_task = asyncio.create_task(
                asyncio.to_thread(self.get_history(session_id).get_messages)
            )
            logger.debug(f"[{session_id}] –ó–∞–ø—É—Å—Ç–∏–ª –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏: —ç–º–±–µ–¥–¥–∏–Ω–≥ + –∏—Å—Ç–æ—Ä–∏—è")

            # –ü–æ–∫–∞ –∂–¥—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥ ‚Äî –º–æ–∂–Ω–æ –Ω–∞—á–∞—Ç—å —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —á–∞—Å—Ç—å –ø—Ä–æ–º–ø—Ç–∞ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            yield "üìö –ò—â—É –¥–æ–∫—É–º–µ–Ω—Ç—ã...\n"

            # –ñ–¥—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥
            try:
                dense = await embedding_task
                embedding_time = time.time() - embedding_start
                logger.debug(f"[{session_id}] ‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥ –ø–æ–ª—É—á–µ–Ω –∑–∞ {embedding_time:.2f} —Å–µ–∫")
            except Exception as e:
                logger.exception(f"[{session_id}] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
                yield "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞."
                return

            if not dense:
                logger.warning(f"[{session_id}] –≠–º–±–µ–¥–¥–∏–Ω–≥ –ø—É—Å—Ç–æ–π –∏–ª–∏ None")
                yield "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞."
                return

            # –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–º–æ–∂–Ω–æ —Ç–æ–∂–µ –æ–±–µ—Ä–Ω—É—Ç—å –≤ —Ç–∞—Å–∫, –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –ø–∞—Ä–∞–ª–ª–µ–ª–∏—Ç—å —Å —á–µ–º-—Ç–æ –µ—â—ë)
            search_start = time.time()
            try:
                docs = await self.retriever(question)
                search_time = time.time() - search_start
                logger.debug(f"[{session_id}] ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞ {search_time:.2f} —Å–µ–∫")
            except Exception as e:
                logger.exception(f"[{session_id}] ‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
                yield "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
                return

            if not docs:
                logger.debug(f"[{session_id}] ‚ùó –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                yield "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."
                return

            yield "‚úÖ –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞–π–¥–µ–Ω—ã. –§–æ—Ä–º–∏—Ä—É—é –æ—Ç–≤–µ—Ç...\n"

            # –ñ–¥—ë–º –∏—Å—Ç–æ—Ä–∏—é
            try:
                hist = await history_task
                hist_time = time.time() - embedding_start  # —Å –º–æ–º–µ–Ω—Ç–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á–∏
                logger.debug(f"[{session_id}] ‚úÖ –ò—Å—Ç–æ—Ä–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {hist_time:.2f} —Å–µ–∫, —Å–æ–æ–±—â–µ–Ω–∏–π: {len(hist)}")
            except Exception as e:
                logger.exception(f"[{session_id}] ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")
                hist = []

            history_text = "\n".join(f"{m.type.capitalize()}: {m.content}" for m in hist)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            context_start = time.time()
            try:
                context, _ = self._build_context(docs, session_id)
                context_time = time.time() - context_start
                context_len = len(context)
                token_count = count_tokens(context) if context else 0
                logger.debug(
                    f"[{session_id}] ‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –∑–∞ {context_time:.2f} —Å–µ–∫, —Ç–æ–∫–µ–Ω–æ–≤: {token_count}, —Å–∏–º–≤–æ–ª–æ–≤: {context_len}")
            except Exception as e:
                logger.exception(f"[{session_id}] ‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
                yield "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."
                return

            if not context:
                logger.warning(f"[{session_id}] –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—É—Å—Ç –ø–æ—Å–ª–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è")
                yield "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."
                return

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ LLM
            prompt = self._build_prompt(
                mode=self.config.MODE,
                question=question,
                context=context,
                history_text=history_text
            )

            full = ""
            buffer = ""
            llm_start = time.time()

            try:
                logger.debug(f"[{session_id}] üß† –ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é LLM...")
                first_token_received = False
                token_count = 0

                async for chunk in self.llm.astream([{"role": "user", "content": prompt}]):
                    if content := chunk.content:
                        if not first_token_received:
                            first_token_time = time.time() - llm_start
                            logger.debug(f"[{session_id}] ‚ö° –ü–µ—Ä–≤—ã–π —Ç–æ–∫–µ–Ω LLM –ø–æ–ª—É—á–µ–Ω –∑–∞ {first_token_time:.2f} —Å–µ–∫")
                            first_token_received = True
                            yield "üß† –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...\n"

                        full += content
                        token_count += 1

                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –∑–Ω–∞–∫ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
                        buffer += content
                        if len(buffer) > 50 or content in ".!?\n":
                            yield buffer
                            buffer = ""

                # –°–∫–∏–¥—ã–≤–∞–µ–º –æ—Å—Ç–∞—Ç–æ–∫
                if buffer:
                    yield buffer

                total_llm_time = time.time() - llm_start
                logger.debug(f"[{session_id}] ‚úÖ LLM —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª {token_count} —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ {total_llm_time:.2f} —Å–µ–∫")

                # --- –≠—Ç–∞–ø 7: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é ---
                save_start = time.time()
                try:
                    history = self.get_history(session_id)
                    history.add_message(HumanMessage(content=question))
                    history.add_message(AIMessage(content=full))
                    save_time = time.time() - save_start
                    logger.debug(f"[{session_id}] üíæ –û—Ç–≤–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –∏—Å—Ç–æ—Ä–∏—é –∑–∞ {save_time:.2f} —Å–µ–∫")
                except Exception as e:
                    logger.exception(f"[{session_id}] ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é: {e}")

            except Exception as e:
                logger.exception(f"[{session_id}] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
                yield "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞."

            total_time = time.time() - start_time
            logger.debug(f"[{session_id}] üéØ –ü–æ–ª–Ω–æ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_time:.2f} —Å–µ–∫")

        self.qa_chain_with_history = generate_answer_stream
        logger.info("QA-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–æ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º –∏ –∏—Å—Ç–æ—Ä–∏–µ–π –Ω–∞—Å—Ç—Ä–æ–µ–Ω")

    async def close(self) -> None:
        # –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Milvus
        await self.milvus.close()