import gradio as gr
import json
from typing import List

from langchain_core.messages import HumanMessage, AIMessage

from config.rag_config import RAGConfig
from core.rag_core import RAGCore
from core.eval import stream_answer_and_evaluate
from core.chat_history import RedisChatHistory

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–π core (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–Ω—É—Ç—Ä–∏ async) ---
cfg = RAGConfig()
core: RAGCore | None = None


# --- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG ---
async def init_rag():
    global core
    if core is None:
        core = RAGCore(cfg)
        core.create_retriever(k=cfg.K, fetch_k=cfg.FETCH_K)
        core.create_qa_generator()
    return core

def load_history(session_id="gradio"):
    store = RedisChatHistory(host="172.20.4.50", session_id=session_id)
    msgs = store.get_messages()

    history = []
    for m in msgs:
        if m.type == "human":
            history.append({"role": "user", "content": m.content})
        elif m.type == "ai":
            history.append({"role": "assistant", "content": m.content})
    return history

# --- –°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ ---
async def chat_answer_stream(message, history, session_id="gradio"):
    rag = await init_rag()

    full_response = ""
    buffer = ""
    async for chunk in rag.qa_chain_with_history(message, session_id=session_id):
        # --- FIX: chunk –º–æ–∂–µ—Ç –±—ã—Ç—å dict ---
        text = chunk.get("text") if isinstance(chunk, dict) else str(chunk)

        buffer += text
        # –æ—Ç–¥–∞—ë–º –ø–∞—Ä—Ç–∏—è–º–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä –∫–∞–∂–¥—ã–µ 10 —Å–∏–º–≤–æ–ª–æ–≤
        if len(buffer) >= 10:
            full_response += buffer
            buffer = ""
            yield full_response

    if buffer:
        full_response += buffer
        yield full_response


# --- –°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π —Ç–µ—Å—Ç —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ ---
async def test_answer_stream(message, keywords_csv, history, session_id="gradio-test"):
    rag = await init_rag()

    expected = [k.strip() for k in (keywords_csv or "").split(",") if k.strip()]
    full_response = ""
    buffer = ""

    async for chunk in stream_answer_and_evaluate(rag, message, expected, session_id=session_id):
        if "[METRICS]" in chunk:
            parts = chunk.split("[METRICS]", 1)
            text_part = parts[0]
            metrics_part = parts[1] if len(parts) > 1 else ""

            if text_part:
                buffer += text_part
                full_response += buffer
                buffer = ""

            try:
                metrics = json.loads(metrics_part.strip())
                pretty = (f"\n\n‚è± {metrics['duration_sec']}s  |  "
                          f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {metrics['keywords_found']}/{metrics['keywords_total']}  |  "
                          f"–ü–æ–∫—Ä—ã—Ç–∏–µ: {metrics['coverage_percent']}%\n"
                          f"–î–µ—Ç–∞–ª–∏: {metrics['found_map']}")
                yield full_response + pretty
            except Exception:
                yield full_response + "\n\n[–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏]"
        else:
            # buffer += chunk
            text = chunk.get("text") if isinstance(chunk, dict) else str(chunk)
            buffer += text
            if len(buffer) >= 10:
                full_response += buffer
                buffer = ""
                yield full_response

    if buffer:
        full_response += buffer
        yield full_response


# --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Gradio ---
with gr.Blocks(title="RAG ‚Äî Streaming UI") as demo:
    gr.Markdown("## üîé RAG QA (Streaming)")
    with gr.Tab("–î–∏–∞–ª–æ–≥"):
        chat = gr.ChatInterface(fn=chat_answer_stream, type="messages", title="QA")
        # # –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ UI ‚Äî –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ–º Redis-–∏—Å—Ç–æ—Ä–∏—é
        # demo.load(lambda: load_history("gradio"), None, chat.chatbot)
    with gr.Tab("–¢–µ—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å"):
        prompt = gr.Textbox(label="–í–æ–ø—Ä–æ—Å")
        keywords = gr.Textbox(label="–û–∂–∏–¥–∞–µ–º—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)")
        out = gr.Textbox(label="–°—Ç—Ä–∏–º –æ—Ç–≤–µ—Ç–∞ + –º–µ—Ç—Ä–∏–∫–∏", lines=12)
        btn = gr.Button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ —Å—Ç—Ä–∏–º–∏—Ç—å –æ—Ç–≤–µ—Ç")
        btn.click(fn=test_answer_stream, inputs=[prompt, keywords, out], outputs=out)

if __name__ == "__main__":
    demo.queue().launch(server_name="0.0.0.0", server_port=7860)
